---
permalink: /
title: "Xiao Yu's Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span style="color:red;">**Thank you for visiting, and welcome to my homepage!üíê**</span>


I am a Master's student in the Cyberspace Security program at the [University of Science and Technology of China](https://www.ustc.edu.cn/). I am very fortunate to be advised by [Prof. Weiming Zhang](https://scholar.google.com/citations?hl=zh-CN&user=eTCfl6cAAAAJ).

I have also had the privilege of being advised by [Prof. Yue Zhang](https://frcchang.github.io/) during my internship at the WestlakeNLP Lab, where I collaborated with [Guangsheng Bao](https://scholar.google.com/citations?user=cxPJx2kAAAAJ&hl=en) on detecting AI-generated texts in the era of Large Reasoning Models.

---

**üçÄResearch Interesets**

My research interests lie in Trustworthy Machine Learning, Large Reasoning Models Security, and AI-generated Text Detection.

- **Large Reasoning Models Security**  
  The rapid emergence of large reasoning models has introduced new challenges in LLM security. Traditional attack methods tend to lose effectiveness against these models due to their advanced reasoning capabilities. My research aims to address two core questions in this space:
  
  - Design **effective and tailored attacks** that expose the vulnerabilities specific to reasoning models, thereby facilitating their robustness and interpretability.
    
  - Explore **unique security risks introduced by reasoning models** that may open up new attack surfaces.
    
- **AI-generated Text Detection and Attribution**  
  Since late 2023, I have been investigating the differences between neural language models and humans, and leveraging these differences to automatically detect AI-generated texts:

  - We introduce the core idea of **semantic decoupling**, which facilitates the development of detection methods with enhanced generalizability across domains.
    
  - As the research evolved, we identified several underexplored yet crucial challenges in this field. For instance, can existing detection methods remain effective as the quality of AI-generated text improves? Reasoning language models, which produce highly fluent and logically coherent content, exemplify this issue. To address this, we developed the first systematic benchmark for evaluating detectors under reasoning-intensive text generation scenarios. Based on this benchmark, we conducted in-depth analyses and proposed detection methods specifically tailored for large reasoning models, aiming to push the frontier of robust and trustworthy AI-generated content detection.
    
---



